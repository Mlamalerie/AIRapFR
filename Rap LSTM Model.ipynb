{"cells":[{"cell_type":"markdown","metadata":{"id":"hp5pH1KCwJrC"},"source":["## Import Librairies"]},{"cell_type":"code","source":[],"metadata":{"id":"GaI-8Ac41d2y","executionInfo":{"status":"ok","timestamp":1675439379459,"user_tz":-60,"elapsed":663,"user":{"displayName":"Mlamali Said Salimo","userId":"18076912819642035214"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":525,"status":"ok","timestamp":1675439381475,"user":{"displayName":"Mlamali Said Salimo","userId":"18076912819642035214"},"user_tz":-60},"id":"Mjfcl1Od_jyd"},"outputs":[],"source":["import os \n","import random\n","import pandas as pd\n","import numpy as np\n","import ast\n","import datetime\n","\n","import matplotlib.pyplot as plt\n","\n","from functools import partial\n","\n","from tqdm import tqdm \n","\n","tqdm.pandas()"]},{"cell_type":"code","source":["!pip install tensorboard"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3JSTWLWq1e3W","executionInfo":{"status":"ok","timestamp":1675439386066,"user_tz":-60,"elapsed":4605,"user":{"displayName":"Mlamali Said Salimo","userId":"18076912819642035214"}},"outputId":"efb45504-9fab-4eb1-a0a8-7722dbf34b63"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.8/dist-packages (2.9.1)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.21.6)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.19.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (57.4.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.4.6)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.51.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.6.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.0.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.38.4)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.16.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.25.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.4.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.4.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard) (6.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.12.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n"]}]},{"cell_type":"code","source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"],"metadata":{"id":"jK8LrKg92HTI","executionInfo":{"status":"ok","timestamp":1675439386067,"user_tz":-60,"elapsed":10,"user":{"displayName":"Mlamali Said Salimo","userId":"18076912819642035214"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2145,"status":"ok","timestamp":1675439388204,"user":{"displayName":"Mlamali Said Salimo","userId":"18076912819642035214"},"user_tz":-60},"id":"M7o7kzk3Ywvi"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.callbacks import LambdaCallback, EarlyStopping,ModelCheckpoint\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Embedding\n","from tensorflow.keras.layers import Dense, Activation, Dropout\n","from tensorflow.keras.layers import LSTM, GRU\n","from tensorflow.keras.optimizers import RMSprop, Adam"]},{"cell_type":"markdown","metadata":{"id":"rfX9_6mUwOEa"},"source":["## Set up drive"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42802,"status":"ok","timestamp":1675439430997,"user":{"displayName":"Mlamali Said Salimo","userId":"18076912819642035214"},"user_tz":-60},"id":"-nEUIZu9wY42","outputId":"4476b149-1ff0-4376-f8ef-c62e6cada98c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4511,"status":"ok","timestamp":1675439435503,"user":{"displayName":"Mlamali Said Salimo","userId":"18076912819642035214"},"user_tz":-60},"id":"2nznAu2rwby-","outputId":"7980078c-2522-473f-ff7c-b1a07b7f23ec"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":6}],"source":["DRIVEWORKSPACE_PATH = \"/content/gdrive/Shareddrives/ING3 (2022-23) Mlamali/10 • Deep Learning/PROJET DL/AIRapFR - ProjetDL\"\n","MODELS_DIR_PATH = f\"{DRIVEWORKSPACE_PATH}/ai/models\"\n","LSTM_MODELS_DIR_PATH = f\"{MODELS_DIR_PATH}/lstm\"\n","\n","os.path.exists(MODELS_DIR_PATH)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1675439435504,"user":{"displayName":"Mlamali Said Salimo","userId":"18076912819642035214"},"user_tz":-60},"id":"XaFMiXMwzgKa"},"outputs":[],"source":["import sys\n","sys.path.append(DRIVEWORKSPACE_PATH)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1593,"status":"ok","timestamp":1675439437090,"user":{"displayName":"Mlamali Said Salimo","userId":"18076912819642035214"},"user_tz":-60},"id":"YDGZnm55wJad"},"outputs":[],"source":["from utils import create_dir"]},{"cell_type":"markdown","metadata":{"id":"zU_oIp-VBPXC"},"source":["## Data"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5592,"status":"ok","timestamp":1675439442677,"user":{"displayName":"Mlamali Said Salimo","userId":"18076912819642035214"},"user_tz":-60},"id":"IARqfBHF319i","outputId":"82f070c6-2e2f-44cb-cba3-8ba172aa947b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<data.load_corpus.CorpusDataManager at 0x7f10df1d0a30>"]},"metadata":{},"execution_count":9}],"source":["from data.load_corpus import CorpusDataManager\n","\n","corpus_dmng = CorpusDataManager()\n","corpus_dmng"]},{"cell_type":"markdown","source":["### load 1 artist corpus"],"metadata":{"id":"M7B-MyMDmunV"}},{"cell_type":"code","source":["df_corpus_keryjames_preprocessed = corpus_dmng.get_df_lyrics_preprocessed_by_name(\"keryjames\")\n","df_corpus_keryjames_preprocessed"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"SYFI4ylBBxOG","executionInfo":{"status":"ok","timestamp":1675439443712,"user_tz":-60,"elapsed":1042,"user":{"displayName":"Mlamali Said Salimo","userId":"18076912819642035214"}},"outputId":"193df8ce-c5b0-45c6-b41a-b45c6d2a1d6d"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading /content/gdrive/Shareddrives/ING3 (2022-23) Mlamali/10 • Deep Learning/PROJET DL/AIRapFR - ProjetDL/data/datasets/genius-1273-keryjames/df_lyrics_preprocessed_tok_crop_.csv\n"]},{"output_type":"execute_result","data":{"text/plain":["         artist  primary_artist.id  \\\n","0    Kery James               1273   \n","1    Kery James               1273   \n","2    Kery James               1273   \n","3    Kery James               1273   \n","4    Kery James               1273   \n","..          ...                ...   \n","153  Kery James               1273   \n","154  Kery James               1273   \n","155  Kery James               1273   \n","156  Kery James               1273   \n","157  Kery James               1273   \n","\n","                                                lyrics       id  \\\n","0    ['mesdames', ',', 'messieurs', ',', 'les', 'pa...   212896   \n","1    ['mes', 'intentions', 'sont', 'bonnes', 'mais'...   319537   \n","2    [\"j'\", 'observe', 'ce', 'qui', 'se', 'passe', ...   422500   \n","3    ['\"', 'il', 'faut', 'cessez', 'le', 'feu', '!'...  3232542   \n","4    ['la', 'plupart', 'de', 'mes', 'amis', 'sont',...  2438741   \n","..                                                 ...      ...   \n","153  ['we', 'should', 'clean', 'you', 'up', 'by', '...  2834826   \n","154  ['les', 'rappeurs', 'racontent', 'des', 'histo...   102532   \n","155  ['ils', 'parlent', 'de', 'nous', '\\n', \"qu'\", ...  2238180   \n","156  ['le', 'morceau', 'qui', 'vient', ',', 'il', '...   103141   \n","157  ['zyed', 'et', 'bouna', '\\n', 'zyed', 'et', 'b...  2340917   \n","\n","                             title  release_date_components.year  \\\n","0                Animalement vôtre                        1999.0   \n","1         Les frères ne savent pas                        2000.0   \n","2              Ce “A” d’avilissant                        2001.0   \n","3                   Cessez le feu!                        2001.0   \n","4                  C’qui nous perd                        2001.0   \n","..                             ...                           ...   \n","153  Racailles English translation                           NaN   \n","154                   Réel {Remix}                           NaN   \n","155               Thug Life - Live                           NaN   \n","156     Vent d’État (version live)                           NaN   \n","157                  Zyed et Bouna                           NaN   \n","\n","                                          artist_names  \\\n","0        Kery James (Ft. Hamed Däye, Rocca & Shurik'n)   \n","1                                           Kery James   \n","2                                           Kery James   \n","3                                           Kery James   \n","4    Kery James (Ft. AP du 113, Demon One, Dry, Jes...   \n","..                                                 ...   \n","153                                         Kery James   \n","154                      Kery James (Ft. Leck & Sadek)   \n","155                                         Kery James   \n","156                                         Kery James   \n","157                                         Kery James   \n","\n","                                      featured_artists language  \n","0    [{'api_path': '/artists/43765', 'header_image_...       fr  \n","1                                                   []       fr  \n","2                                                   []       fr  \n","3                                                   []       fr  \n","4    [{'api_path': '/artists/2406499', 'header_imag...       fr  \n","..                                                 ...      ...  \n","153                                                 []       en  \n","154  [{'api_path': '/artists/15237', 'header_image_...       fr  \n","155                                                 []       fr  \n","156                                                 []       fr  \n","157                                                 []       fr  \n","\n","[158 rows x 9 columns]"],"text/html":["\n","  <div id=\"df-527462e3-fbce-4b80-aecf-6c7652c549b4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>artist</th>\n","      <th>primary_artist.id</th>\n","      <th>lyrics</th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>release_date_components.year</th>\n","      <th>artist_names</th>\n","      <th>featured_artists</th>\n","      <th>language</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kery James</td>\n","      <td>1273</td>\n","      <td>['mesdames', ',', 'messieurs', ',', 'les', 'pa...</td>\n","      <td>212896</td>\n","      <td>Animalement vôtre</td>\n","      <td>1999.0</td>\n","      <td>Kery James (Ft. Hamed Däye, Rocca &amp; Shurik'n)</td>\n","      <td>[{'api_path': '/artists/43765', 'header_image_...</td>\n","      <td>fr</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Kery James</td>\n","      <td>1273</td>\n","      <td>['mes', 'intentions', 'sont', 'bonnes', 'mais'...</td>\n","      <td>319537</td>\n","      <td>Les frères ne savent pas</td>\n","      <td>2000.0</td>\n","      <td>Kery James</td>\n","      <td>[]</td>\n","      <td>fr</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Kery James</td>\n","      <td>1273</td>\n","      <td>[\"j'\", 'observe', 'ce', 'qui', 'se', 'passe', ...</td>\n","      <td>422500</td>\n","      <td>Ce “A” d’avilissant</td>\n","      <td>2001.0</td>\n","      <td>Kery James</td>\n","      <td>[]</td>\n","      <td>fr</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Kery James</td>\n","      <td>1273</td>\n","      <td>['\"', 'il', 'faut', 'cessez', 'le', 'feu', '!'...</td>\n","      <td>3232542</td>\n","      <td>Cessez le feu!</td>\n","      <td>2001.0</td>\n","      <td>Kery James</td>\n","      <td>[]</td>\n","      <td>fr</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Kery James</td>\n","      <td>1273</td>\n","      <td>['la', 'plupart', 'de', 'mes', 'amis', 'sont',...</td>\n","      <td>2438741</td>\n","      <td>C’qui nous perd</td>\n","      <td>2001.0</td>\n","      <td>Kery James (Ft. AP du 113, Demon One, Dry, Jes...</td>\n","      <td>[{'api_path': '/artists/2406499', 'header_imag...</td>\n","      <td>fr</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>153</th>\n","      <td>Kery James</td>\n","      <td>1273</td>\n","      <td>['we', 'should', 'clean', 'you', 'up', 'by', '...</td>\n","      <td>2834826</td>\n","      <td>Racailles English translation</td>\n","      <td>NaN</td>\n","      <td>Kery James</td>\n","      <td>[]</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>154</th>\n","      <td>Kery James</td>\n","      <td>1273</td>\n","      <td>['les', 'rappeurs', 'racontent', 'des', 'histo...</td>\n","      <td>102532</td>\n","      <td>Réel {Remix}</td>\n","      <td>NaN</td>\n","      <td>Kery James (Ft. Leck &amp; Sadek)</td>\n","      <td>[{'api_path': '/artists/15237', 'header_image_...</td>\n","      <td>fr</td>\n","    </tr>\n","    <tr>\n","      <th>155</th>\n","      <td>Kery James</td>\n","      <td>1273</td>\n","      <td>['ils', 'parlent', 'de', 'nous', '\\n', \"qu'\", ...</td>\n","      <td>2238180</td>\n","      <td>Thug Life - Live</td>\n","      <td>NaN</td>\n","      <td>Kery James</td>\n","      <td>[]</td>\n","      <td>fr</td>\n","    </tr>\n","    <tr>\n","      <th>156</th>\n","      <td>Kery James</td>\n","      <td>1273</td>\n","      <td>['le', 'morceau', 'qui', 'vient', ',', 'il', '...</td>\n","      <td>103141</td>\n","      <td>Vent d’État (version live)</td>\n","      <td>NaN</td>\n","      <td>Kery James</td>\n","      <td>[]</td>\n","      <td>fr</td>\n","    </tr>\n","    <tr>\n","      <th>157</th>\n","      <td>Kery James</td>\n","      <td>1273</td>\n","      <td>['zyed', 'et', 'bouna', '\\n', 'zyed', 'et', 'b...</td>\n","      <td>2340917</td>\n","      <td>Zyed et Bouna</td>\n","      <td>NaN</td>\n","      <td>Kery James</td>\n","      <td>[]</td>\n","      <td>fr</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>158 rows × 9 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-527462e3-fbce-4b80-aecf-6c7652c549b4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-527462e3-fbce-4b80-aecf-6c7652c549b4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-527462e3-fbce-4b80-aecf-6c7652c549b4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["### load rap corpus"],"metadata":{"id":"0I-31RbZm2wL"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vTWJ8ocFArzF","outputId":"4ac2e3c5-6897-4bbe-b9e1-affdd9cf9582"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading 262 csv files\n"]},{"output_type":"stream","name":"stderr","text":[" 95%|█████████▍| 248/262 [04:09<00:14,  1.02s/it]"]}],"source":["df_corpus_preprocessed = corpus_dmng.get_full_df_lyrics_corpus(preprocessed=True, only_french_artist=True)\n","df_corpus_preprocessed.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nWAZpeNkayFO"},"outputs":[],"source":["df_corpus_preprocessed.info()"]},{"cell_type":"code","source":["df_corpus_preprocessed[\"release_date_components.year\"] = df_corpus_preprocessed[\"release_date_components.year\"].where(df_corpus_preprocessed[\"release_date_components.year\"] >= 1800, np.nan)\n","\n","df_corpus_preprocessed[\"release_date_components.year\"].describe()"],"metadata":{"id":"cOGqK1jA4ese"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_corpus_preprocessed[\"release_date_components.year\"].isna().sum()"],"metadata":{"id":"w2lCfZPn7Pkc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tri par artiste et album.name\n","df_corpus_preprocessed = df_corpus_preprocessed.sort_values(by=[\"artist\",\"artist_names\", \"album.name\",\"release_date_components.year\"]).reset_index(drop=True)\n","\n","# Remplacer les valeurs NaN de la colonne \"year\" par la valeur de la même colonne du même artiste\n","df_corpus_preprocessed[\"release_date_components.year\"] = df_corpus_preprocessed[\"release_date_components.year\"].fillna(method=\"ffill\", limit=1)"],"metadata":{"id":"NKF9qazL7Ow-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_corpus_preprocessed[\"release_date_components.year\"].plot.hist()\n","df_corpus_preprocessed[\"release_date_components.year\"].describe()"],"metadata":{"id":"VpyQ_Bne5etm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_year_filter = 2008\n","df_corpus_preprocessed = df_corpus_preprocessed[df_corpus_preprocessed[\"release_date_components.year\"] < max_year_filter].reset_index(drop=True)\n","df_corpus_preprocessed.shape"],"metadata":{"id":"CaND_gf14YlZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_VTmU85efU66"},"source":["### Format"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-J4pMKX4f_M4"},"outputs":[],"source":["type(df_corpus_preprocessed[\"lyrics\"][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RnIZmkYDfXjX"},"outputs":[],"source":["df_corpus_preprocessed[\"lyrics\"] = df_corpus_preprocessed[\"lyrics\"].progress_apply(ast.literal_eval)\n","type(df_corpus_preprocessed[\"lyrics\"][0])"]},{"cell_type":"markdown","metadata":{"id":"ewq5uZKgbz83"},"source":["### Tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B_drpThRaQdb"},"outputs":[],"source":["full_corpus_tokens = df_corpus_preprocessed[\"lyrics\"].explode().tolist()\n","\n","for i in [random.randint(0,len(full_corpus_tokens)-1) for _ in range(5)]:\n","    print(full_corpus_tokens[i:i+10])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HyK-tK_zY32Y"},"outputs":[],"source":["print('Corpus length in characters:', sum([len(token) for token in full_corpus_tokens]))\n","print('Corpus length in words:', len(full_corpus_tokens))"]},{"cell_type":"markdown","metadata":{"id":"iCPlpEnVhWPg"},"source":["#### Word Frequency"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OsIV3H0NhYbX"},"outputs":[],"source":["table_tokens_value_counts = df_corpus_preprocessed[\"lyrics\"].explode().value_counts()\n","table_tokens_value_counts"]},{"cell_type":"markdown","metadata":{"id":"E6FUj4x0h3zk"},"source":["#### Ignore Words\n","\n","Ignorer les mots les moins fréquents dans le processus de création d'un LSTM pour générer des textes de rap peut améliorer la qualité des résultats en réduisant le bruit dans les données d'entraînement. Les mots les plus rares sont souvent des erreurs de frappe, des mots spécifiques à une langue ou des mots qui n'ont aucun sens dans le contexte du texte. En les éliminant, on peut se concentrer sur les mots plus significatifs et pertinents pour la tâche de génération de textes de rap, ce qui peut conduire à des modèles plus précis et à des générations de textes plus cohérentes et de meilleure qualité."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OxgikcnDh-lZ"},"outputs":[],"source":["MIN_WORD_FREQUENCY=3 # 450\n","\n","table_tokens_value_counts[table_tokens_value_counts < MIN_WORD_FREQUENCY]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mOSz2ZlZh3S4"},"outputs":[],"source":["ignored_words = set(table_tokens_value_counts[table_tokens_value_counts < MIN_WORD_FREQUENCY].index.tolist())\n","len(ignored_words)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6P2f7Faen_sT"},"outputs":[],"source":["words = set(full_corpus_tokens)\n","print('Unique words before ignoring:', len(words))\n","print('Ignoring words with frequency <', MIN_WORD_FREQUENCY)\n","words = sorted(words - ignored_words)\n","print('Unique words after ignoring:', len(words))"]},{"cell_type":"markdown","metadata":{"id":"JUcmwP_Qb6Qb"},"source":["### Indexation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NuKIQY0mpe3L"},"outputs":[],"source":["word_indices = dict((c, i) for i, c in enumerate(words))\n","indices_word = dict((i, c) for i, c in enumerate(words))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C0hgaqYTpoW3"},"outputs":[],"source":["# cut the text in semi-redundant sequences of SEQUENCE_LEN words\n","SEQUENCE_LEN = 10\n","STEP = 1 # chaque séquence suivante sera décalée d'un seul mot par rapport à la séquence précédente.\n","sentences_dataset = []\n","next_words_dataset = []\n","ignored = 0\n","for i in tqdm(range(0, len(full_corpus_tokens) - SEQUENCE_LEN, STEP)):\n","    # Only add sequences where no word is in ignored_words\n","    if len(set(full_corpus_tokens[i: i+SEQUENCE_LEN+1]).intersection(ignored_words)) == 0:\n","        sentences_dataset.append(full_corpus_tokens[i: i + SEQUENCE_LEN])\n","        next_words_dataset.append(full_corpus_tokens[i + SEQUENCE_LEN])\n","    else:\n","        ignored = ignored+1\n","\n","print()\n","print('Ignored sequences:', ignored)\n","print('Remaining sequences:', len(sentences_dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eiN4uHsTq7t7"},"outputs":[],"source":["len(sentences_dataset), len(next_words_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KZ7mQDy2rGCX"},"outputs":[],"source":["sentences_dataset[2], next_words_dataset[2]"]},{"cell_type":"markdown","metadata":{"id":"bVbo_Ivzb8za"},"source":["### Padding"]},{"cell_type":"markdown","metadata":{"id":"IoiBsRClrtMV"},"source":["### Shuffle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tYIb9k-ctAl9"},"outputs":[],"source":["def split_training_and_test_set(sentences_original, next_original, percentage_test=0.1,seed=123):\n","    # shuffle the data in unison\n","    np.random.seed(seed)\n","    shuffled_indices = np.random.permutation(len(sentences_original))\n","    sentences_shuffled = [sentences_original[i] for i in shuffled_indices]\n","    next_words_shuffled = [next_original[i] for i in shuffled_indices]\n","\n","    # split the data into training and test sets\n","    cut_index = int(len(sentences_original) * percentage_test)\n","    x_test,x_train  = sentences_shuffled[:cut_index], sentences_shuffled[cut_index:]\n","    y_test,y_train  = next_words_shuffled[:cut_index], next_words_shuffled[cut_index:]\n","\n","    print(\"Size of training set = %d\" % len(x_train))\n","    print(\"Size of test set = %d\" % len(y_test))\n","    return (x_train, y_train), (x_test, y_test)\n","\n","(sentences_train, next_words_train), (sentences_test, next_words_test) = split_training_and_test_set(sentences_dataset, next_words_dataset)  \n","\n","sentences_train[1], next_words_train[1]"]},{"cell_type":"markdown","metadata":{"id":"JOwQvFAFvGIo"},"source":["todo : faire fonction script qui générer train_set et set set auto"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hu274NWQvgZs"},"outputs":[],"source":["def sample(preds, temperature=1.0):\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)    "]},{"cell_type":"markdown","metadata":{"id":"TnSa0XcJzQ7l"},"source":["## Model Building\n"]},{"cell_type":"markdown","metadata":{"id":"mTc1Y5A4wbh-"},"source":["### ..."]},{"cell_type":"markdown","metadata":{"id":"5ZJcYE5AwjtR"},"source":["La fonction `generator` sert à générer des données pour entraîner le modèle réseau de neurones LSTM. Elle prend en entrée des listes de phrases et de mots suivants, ainsi qu'une taille de batch, et renvoie des entrées et sorties pour l'entraînement."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VQJgnIcSweet"},"outputs":[],"source":["def data_generator(sentence_list, next_word_list, batch_size, sequence_length, words_dict):\n","    index = 0\n","    while True:\n","        x = np.zeros((batch_size, sequence_length, len(words_dict)), dtype=bool)\n","        y = np.zeros((batch_size, len(words_dict)), dtype=bool)\n","        for i in range(batch_size):\n","            for t, w in enumerate(sentence_list[index]):\n","                x[i, t, words_dict[w]] = 1\n","            y[i, words_dict[next_word_list[index]]] = 1\n","\n","            index = (index + 1) % len(sentence_list)\n","        yield x, y\n","\n","partial_data_generator = partial(data_generator,sequence_length=SEQUENCE_LEN,words_dict=word_indices)\n","\n","for x,y in partial_data_generator(sentences_train, next_words_train, batch_size=128):\n","    print(x.shape)\n","    print(y.shape)\n","    break"]},{"cell_type":"markdown","metadata":{"id":"TCyGyvEpB6by"},"source":["### Model 1 : LSTM\n","\n","Building the LSTM Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FvzWNepMYWlG"},"outputs":[],"source":["model_lstm_1 = Sequential(name=\"model_lstm_1\")\n","model_lstm_1.add(LSTM(128, input_shape=(SEQUENCE_LEN, len(words))))\n","model_lstm_1.add(Dense(len(words)))\n","model_lstm_1.add(Activation('softmax'))\n","model_lstm_1.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01), metrics=['accuracy'])\n","model_lstm_1.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f4yBw4WHb0WD"},"outputs":[],"source":["word_indices['\\n']"]},{"cell_type":"code","source":["SEQUENCE_LEN"],"metadata":{"id":"7Kn6l3ZliwLp"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ZUGpnmv9HMw"},"outputs":[],"source":["def generate_text(model, starting_words,window_size, words_indices, indices_words, max_length=50, diversity=1):\n","    assert max_length > len(starting_words),\"max_length must > len(starting_words)\"\n","    length = max_length - len(starting_words)\n","    \n","    generated = starting_words\n","    sentence = starting_words[-window_size:]\n","    for i in range(length):\n","        x_pred = np.zeros((1, window_size, len(words)))\n","        #print(sentence)\n","        for t, word in enumerate(sentence):\n","            x_pred[0, t, words_indices[word]] = 1.\n","\n","        preds = model.predict(x_pred, verbose=0)[0]\n","        \n","        next_index = sample(preds, diversity)\n","        next_word = indices_words[next_index]\n","        #print(generated)\n","        generated.append(next_word)\n","        sentence = sentence[-(window_size-1):] + [next_word]\n","    return generated\n","\n","generate_text(model_lstm_1, ['je',\"suis\"],window_size=SEQUENCE_LEN, words_indices=word_indices, indices_words=indices_word, diversity=1.0, max_length=50)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0w-9jDdbvkmX"},"outputs":[],"source":["def on_epoch_end(epoch, logs, model, sequence_len, words_indices, indices_words, max_diversity=1.0, max_length=10,epochs_looked = [0,25,50]):\n","    if epoch in epochs_looked:\n","        print(f'\\n----- Generating text after Epoch: {epoch}')\n","        for diversity in np.linspace(0.2, max_diversity, 3):\n","            print(f'----- Diversity: {diversity}')\n","            generated_text = generate_text(model, ['je',\"suis\"],window_size=sequence_len, words_indices=word_indices, indices_words=indices_word, diversity=diversity, max_length=max_length)\n","            \n","            print(' '.join(generated_text))\n","\n","\"\"\"\n","def on_epoch_end_orig(epoch, logs):\n","    print()\n","    if(epoch > 45):\n","        print('----- Generating text after Epoch: %d\\n' % epoch)\n","        for diversity in [0.2, 0.5, 1.0]:\n","            \n","            print('----- Diversity:', diversity, ' -----')\n","            generated = ['je','suis', 'né']\n","            sentence = generated\n","            for i in range(100):\n","                \n","                x_pred = np.zeros((1, SEQUENCE_LEN, len(words)))\n","                for t, word in enumerate(sentence):\n","                    x_pred[0, t, word_indices[word]] = 1.\n","        \n","                preds = model_lstm_1.predict(x_pred, verbose=0)[0]\n","                next_index = sample(preds, diversity)\n","                next_word = indices_word[next_index]\n","                generated.append(next_word)\n","                sentence = sentence[1:] + [next_word]\n","                sys.stdout.write(next_word)\n","                sys.stdout.flush()\n","                \n","            print()\n","\n","\"\"\"\n"]},{"cell_type":"markdown","metadata":{"id":"qQvekiCVw3zu"},"source":["#### Pre-training \n","\n","on fr rappers corpus"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"00cn-__Ew_np"},"outputs":[],"source":["batch_size = 128\n","epochs = 50"]},{"cell_type":"markdown","source":["##### checkpoint"],"metadata":{"id":"yZjlY35H0Nhx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mjcIop6Lczdj"},"outputs":[],"source":["weights_file = LSTM_MODELS_DIR_PATH + \"/pre-trained/\" + f\"{model_lstm_1.name}.hdf5\"\n","checkpoint = ModelCheckpoint(weights_file, monitor='val_loss',  save_best_only=True, save_weights_only=False) \n","\n","if os.path.exists(weights_file):\n","    model_lstm_1.load_weights(weights_file)\n","    print(\"Chargé les poids précédents\")\n","else:\n","    print(\"Pas de poids précédents trouvés, entraînement à partir de zéro\")\n","                                               "]},{"cell_type":"markdown","source":["##### early stopping"],"metadata":{"id":"NSsRLjs5719M"}},{"cell_type":"code","source":["early_stopping = EarlyStopping(monitor='val_loss', patience=5)"],"metadata":{"id":"j1t9R1MUx3lT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### print on epoch end"],"metadata":{"id":"_G3BbnZo74tv"}},{"cell_type":"code","source":["print_callback_orig = LambdaCallback(on_epoch_end=partial(on_epoch_end, model=model_lstm_1, sequence_len=SEQUENCE_LEN, words_indices=word_indices, indices_words=indices_word, max_diversity=1.0, max_length=50,epochs_looked = [0,5,10,25,50])\n",")    "],"metadata":{"id":"ABAR7YShwRKa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### tensorboard"],"metadata":{"id":"wQMP8BNH8CFl"}},{"cell_type":"code","source":["!mkdir logs"],"metadata":{"id":"7AmKi5uD87fM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"],"metadata":{"id":"csEJkFfu7tvf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorboard --logdir logs"],"metadata":{"id":"xbgzyhmn2iAX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-bgWSyEUv6HW"},"outputs":[],"source":["history_lstm_1 = model_lstm_1.fit(partial_data_generator(sentences_train, next_words_train, batch_size=batch_size),\n","                              steps_per_epoch=int(len(sentences_dataset)/batch_size) + 1,\n","                              epochs=50,\n","                              callbacks=[print_callback_orig,checkpoint,early_stopping,tensorboard_callback],\n","                              validation_data=partial_data_generator(sentences_test, next_words_test, batch_size=batch_size), \n","                              validation_steps=int(len(sentences_test)/batch_size) + 1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1x6-OBKJ7azw"},"outputs":[],"source":["def plot_learning_curves(history, title=\"\"):\n","    acc      = history.history[\"accuracy\"]\n","    loss     = history.history[\"loss\"]\n","    val_acc  = history.history[\"val_accuracy\"]\n","    val_loss = history.history[\"val_loss\"]\n","    epochs = range(len(acc))\n","\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n","    \n","    fig.suptitle(title, fontsize=\"x-large\")\n","    \n","    ax1.plot(epochs, acc, label=\"Entraînement\")\n","    ax1.plot(epochs, val_acc, label=\"Validation\")\n","    ax1.set_title(\"Accuracy - Données entraînement vs. validation.\")\n","    ax1.set_ylabel(\"Accuracy (%)\")\n","    ax1.set_xlabel(\"Epoch\")\n","    ax1.legend()\n","    \n","    ax2.plot(epochs, loss, label=\"Entraînement\")\n","    ax2.plot(epochs, val_loss, label=\"Validation\")\n","    ax2.set_title(\"Perte - Données entraînement vs. validation.\")\n","    ax2.set_ylabel('Perte')\n","    ax2.set_xlabel('Epoch')\n","    ax2.legend()\n","\n","    fig.show()\n","\n","plot_learning_curves(history_lstm_1, title=\"Modèle LSTM (simple)\")"]},{"cell_type":"markdown","metadata":{"id":"bvrnbTCt1Jwt"},"source":["##### save"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3EI-JpU7rIiJ"},"outputs":[],"source":["weights_file = LSTM_MODELS_DIR_PATH + \"/pre-trained/\" + f\"{model_lstm_1.name}.hdf5\"\n","model_lstm_1.save(weights_file)\n","del model_lstm_1"]},{"cell_type":"markdown","metadata":{"id":"N5poewDUCEGW"},"source":["##### load and testing"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":940,"status":"ok","timestamp":1675414453111,"user":{"displayName":"Mlamali Said Salimo","userId":"18076912819642035214"},"user_tz":-60},"id":"X7yUrkSy37Aa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"45992ed7-1e76-49b8-99b1-446888234499"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.engine.sequential.Sequential at 0x7f36a6338700>"]},"metadata":{},"execution_count":41}],"source":["weights_file = LSTM_MODELS_DIR_PATH + \"/pre-trained/\" + f\"{model_lstm_1.name}.hdf5\"\n","model_lstm_1 = load_model(weights_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10915,"status":"ok","timestamp":1675414645441,"user":{"displayName":"Mlamali Said Salimo","userId":"18076912819642035214"},"user_tz":-60},"id":"4kI31yperKvC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"64ca9d29-c034-4099-8581-d1477085cabb"},"outputs":[{"output_type":"stream","name":"stdout","text":["----- Generating text -----\n","\n","----- Diversity: 0.2  -----\n","\n","le rap vaincu baisser bouffe mieux pleines jungle pavé détenu succès innocence meurt permet mange rg perm tempête tieks vivra système aies knight prenne effacer kicker lopes salles étouffe rebeu comoco horizon décor reup enterré miami anciens clés gorge descendre dépensé pouvait chiennes soin souffre dégomme favori part si rôle dédicace testament\n","\n","----- Diversity: 0.5  -----\n","\n","le rap piles échelle réagit hi bingo décolle choisir verras renards mia geyser alerte péchés meurtres cramé monté rumeurs dise tension magie début sacré échappe impasse pouvoir original g.a.v z incarne feux baiser tendre payes vi ailleurs hosto arriver défoncer real hit solides foutre leçons valide ramadan rêve peureux appeler pince préfères\n","\n","----- Diversity: 1.0  -----\n","\n","le rap traquent shut rivaliser bus 24 { dépôt écrase mal-être conforme émissions ouverts profond tentations enfoiré sauter celles ha cjd fenêtres us affaires garçons bizz en inch' couille peace narines parfait premiers faisais happy fringues maillot -là tien mosquée ak-47 même r.o.h.f.f course créé police jure pompiers cité opération big percutant\n","----- Text generation complete! -----\n"]}],"source":["\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YCJ4EZGJB_vc"},"source":["#### Fine-tuning\n"," on 1 artist corpus "]},{"cell_type":"code","source":["# Charger les poids du modèle précédemment entraîné\n","model.load_weights(\"path/to/pre-trained/weights.h5\")\n","\n","# Compiler à nouveau le modèle\n","model.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Entraîner le modèle sur les données de l'artiste particulier\n","history = model.fit(artist_data_generator,\n","                    steps_per_epoch=int(len(artist_sentences)/batch_size) + 1,\n","                    epochs=50,\n","                    callbacks=[early_stopping],\n","                    validation_data=artist_data_generator,\n","                    validation_steps=int(len(artist_sentences_test)/batch_size) + 1)"],"metadata":{"id":"R37xEMYAzmxb"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}